{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-10 17:18:35.009352: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-04-10 17:18:35.092743: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-04-10 17:18:35.094111: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-10 17:18:36.939674: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf \n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.losses import BinaryCrossentropy\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the dataset (replace 'data.csv' with the path to your dataset)\n",
    "data = pd.read_csv('sample_Datasets.csv')\n",
    "\n",
    "# Preprocess the data\n",
    "# Convert Time of Day to seconds\n",
    "data['Time of Day'] = pd.to_datetime(data['Time of Day']).dt.hour * 3600 + pd.to_datetime(data['Time of Day']).dt.minute * 60 + pd.to_datetime(data['Time of Day']).dt.second\n",
    "\n",
    "# One-hot encode the 'Location' and 'Purchase' columns\n",
    "data = pd.get_dummies(data, columns=['Location', 'Transaction'])\n",
    "\n",
    "# Scale the features using MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "data[['Amount', 'Time of Day']] = scaler.fit_transform(data[['Amount', 'Time of Day']])\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X = data.drop(columns=['Fraudulent'])\n",
    "y = data['Fraudulent']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "\n",
    "# Build the ANN model\n",
    "input_shape = X_train.shape[1]\n",
    "\n",
    "model = Sequential([\n",
    "    Dense(64, activation='relu', input_shape=(input_shape,)),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss=BinaryCrossentropy(), metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, epochs=3, batch_size=32, validation_split=0.1)\n",
    "\n",
    "# Evaluate the model on the testing set\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f'Test Loss: {loss}, Test Accuracy: {accuracy}')\n",
    "\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = (model.predict(X_test) > 0.5).astype(\"int32\")\n",
    "\n",
    "# Calculate performance metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "conf_mat = confusion_matrix(y_test, y_pred)\n",
    "print('\\n')\n",
    "print('\\n')\n",
    "print('\\n')\n",
    "print('======================================== Performance Metrics ======================================== ')\n",
    "\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print(f'Precision: {precision}')\n",
    "print(f'Recall: {recall}')\n",
    "print(f'F1-score: {f1}')\n",
    "print(f'Confusion Matrix:\\n {conf_mat}')\n",
    "print('\\n')\n",
    "print('\\n')\n",
    "input(\"Press Enter to continue...\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# history = model.fit(X_train, y_train, epochs=50, batch_size=32, validation_split=0.1)\n",
    "\n",
    "# Plot training & validation accuracy values\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
